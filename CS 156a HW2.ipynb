{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 156 HW 1\n",
    "### Ankush Hommerich-Dutt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  100000  iterations of 1000 coins flipped 10 times.\n",
      "The average value of v_min is:  0.03783\n",
      "The average value of v_1 is:  0.500831\n",
      "The average value of v_rand is:  0.49919\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import timeit\n",
    "\n",
    "class Coin:\n",
    "    def __init__(self):\n",
    "        self.outcomes = []\n",
    "    \n",
    "    def flip(self):\n",
    "        rand = random.random()\n",
    "        if rand < 0.5:\n",
    "            self.outcomes.append('t')\n",
    "        else:\n",
    "            self.outcomes.append('h')\n",
    "    \n",
    "def main(n):\n",
    "    v_1 = [0] * n\n",
    "    v_rand = [0] * n\n",
    "    v_min = [0] * n\n",
    "    coins = [Coin() for j in range(1000)]\n",
    "    for i in range(n):\n",
    "        min_heads = 11\n",
    "        for coin in coins:\n",
    "            for j in range(10):\n",
    "                coin.flip()\n",
    "            num_heads = coin.outcomes.count('h')\n",
    "            if num_heads < min_heads:\n",
    "                min_heads = num_heads\n",
    "        \n",
    "        v_min[i] = min_heads\n",
    "        \n",
    "        v_1[i] = coins[0].outcomes.count('h')\n",
    "        v_rand[i] = coins[random.randint(0,999)].outcomes.count('h')\n",
    "        \n",
    "        for coin in coins:\n",
    "            coin.outcomes = []  \n",
    "    \n",
    "    v_1_avg = (sum(v_1) / n) / 10\n",
    "    v_rand_avg = (sum(v_rand) / n) / 10\n",
    "    v_min_avg = (sum(v_min) / n) / 10\n",
    "    \n",
    "    print(\"Running \", n, \" iterations of 1000 coins flipped 10 times.\")\n",
    "    print(\"The average value of v_min is: \", v_min_avg)\n",
    "    print(\"The average value of v_1 is: \", v_1_avg)\n",
    "    print(\"The average value of v_rand is: \", v_rand_avg)\n",
    "\n",
    "main(100000)            \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[b]**\n",
    "\n",
    "The average value calculated for $\\nu_{\\text{min}}$ is  0.037 which is closest to 0.01 out of the answer choices. The code to get this result is above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **[d]**\n",
    "\n",
    "Hoeffding inequality: $\\mathbb P[|\\nu - \\mu| > \\epsilon] \\leq 2e^{-2\\epsilon^2N}$\n",
    "\n",
    "$\\mu$ for a coin flip is 0.5. \n",
    "\n",
    "For $\\nu_{\\text{min}}$, |\\nu - \\mu| = |0.0378 - 0.5| = 0.4622 \n",
    "\n",
    "If we plug in 0.4622 as epsilon into the Hoeffding inequality, we get $e^{-2000(0.4622)^2} = 2.78 \\times 10^{-186}$ which is a very low probability (next to none), and so this distribution does not satisfy the Hoeffding inequality. This distribution for $\\nu$ will never happen if our $\\mu$ was actually 0.5 \n",
    "\n",
    "For $\\nu_{\\text{1}}$, |\\nu - \\mu| = |0.5008 - 0.5| = 0.0008\n",
    "\n",
    "If we plug in 0.008 as epsilon into the Hoeffding inequality, we get $e^{-2000(0.0008)^2} = .9987$ which is a very high probability. This distribution for $\\nu$ is very likely to occur given that our $\\mu$ is 0.5, and so we can safely say that the $c_{\\text{1}}$ distribution satisfies Hoeffding.\n",
    "\n",
    "For $\\nu_{\\text{rand}}$, |\\nu - \\mu| = |0.4992 - 0.5| = 0.0008\n",
    "\n",
    "If we plug in 0.008 as epsilon into the Hoeffding inequality, we get $e^{-2000(0.0008)^2} = .9987$ which is a very high probability. This distribution for $\\nu$ is very likely to occur given that our $\\mu$ is 0.5, and so we can safely say that the $c_{\\text{rand}}$ distribution satisfies Hoeffding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **[e]** \n",
    "\n",
    "The probability of $h$ approximating $y$ incorrectly given the noisy $f$ is the probability of $h$ approximating $f$ correctly when $f$ gets $y$ wrong, plus the probability of $h$ approximating $f$ incorrectly when $f$ gets $y$ right. \n",
    "Expressing this mathematically in terms of the variables defined in the problem, this is the same as:\n",
    "\n",
    "$[(1 - \\lambda) * (1 - \\mu)] + [\\lambda * \\mu]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **[b]**\n",
    "\n",
    "If we expand out the expression from the previous answer of the probability of error:\n",
    "\n",
    "$[(1 - \\lambda) * (1 - \\mu)] + [\\lambda * \\mu] = 1 +\\mu\\lambda - \\lambda - \\mu + \\mu\\lambda = 1 + 2\\mu\\lambda - \\lambda - \\mu = 1 + \\mu(2\\lambda - 1) - \\lambda$\n",
    "\n",
    "If $\\lambda = 0.5$, then the $\\mu$ term in the error expression goes to 0, and our probability of error is $1 - 0.5 = 0.5$, regardless of what $\\mu$ is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 100: \n",
      "E_in:  0.04007000000000012\n",
      "E_out:  0.05046499999999996\n",
      "N = 10: \n",
      "Average number of iterations for PLA to converge:  6.229\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.val = np.array([1, x, y])\n",
    "        \n",
    "    def outcome(self, line):\n",
    "        target = line.evaluate(self.val[1])\n",
    "        if self.val[2] > target:\n",
    "            return 1\n",
    "        return -1\n",
    "        \n",
    "class Line:\n",
    "    def __init__(self, point1, point2):\n",
    "        self.slope = (point2.val[2] - point1.val[2]) / (point2.val[1] - point1.val[1])\n",
    "        self.intercept = (self.slope * (-point1.val[1])) + point1.val[2]\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        return (self.slope * x) + self.intercept\n",
    "    \n",
    "        \n",
    "def random_point():\n",
    "    return Point(random.uniform(-1,1), random.uniform(-1,1))\n",
    "\n",
    "def target_function():\n",
    "    point1 = random_point()\n",
    "    point2 = random_point()\n",
    "    return Line(point1, point2)\n",
    "\n",
    "class Weight_vector:\n",
    "    def __init__(self):\n",
    "        self.vec = np.array([0,0,0]) \n",
    "    \n",
    "    def update(self, y, point):\n",
    "        self.vec[0] += y*point.val[0]\n",
    "        self.vec[1] += y*point.val[1]\n",
    "        self.vec[2] += y*point.val[2]\n",
    "\n",
    "def iteration(outcomes, weight_vec, target):\n",
    "    mis = [i[0] for i in outcomes if np.sign(weight_vec.vec.dot(i[0].val)) != i[1]]\n",
    "    if len(mis) == 0:\n",
    "        return True\n",
    "    bad_point = mis[random.randint(0,len(mis) - 1)]\n",
    "    weight_vec.update(bad_point.outcome(target), bad_point)\n",
    "    \n",
    "    return False\n",
    "\n",
    "    \n",
    "def main(n):\n",
    "    target = target_function()\n",
    "    data = [random_point() for x in range(n)]\n",
    "    outcomes =  list(map(lambda x: (x,x.outcome(target)), data))\n",
    "\n",
    "    X = np.zeros((n, 3))\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        X[i,:] = outcomes[i][0].val\n",
    "        y[i] = outcomes[i][1]\n",
    "        \n",
    "    w = Weight_vector()\n",
    "        \n",
    "    w.vec = (LA.inv(X.T@X)@(X.T))@y   \n",
    "    #w = LA.pinv(X)@y\n",
    "    \n",
    "    mis = 0\n",
    "    for i in range(n):\n",
    "        if np.sign(w.vec.dot(data[i].val)) != outcomes[i][1]:\n",
    "            mis += 1\n",
    "        \n",
    "    E_in = mis / n\n",
    "    \n",
    "    new_data = [random_point() for x in range(1000)]\n",
    "    new_outcomes =  list(map(lambda x: (x, x.outcome(target)), new_data))\n",
    "    mis = [1 for i in new_outcomes if np.sign(w.vec.dot(i[0].val)) != i[1]]\n",
    "    prob = len(mis) / 1000\n",
    "    \n",
    "    converge = False \n",
    "    num_iterations = 0\n",
    "    while converge != True:\n",
    "        converge = iteration(outcomes, w, target)\n",
    "        num_iterations += 1\n",
    "    \n",
    "    return E_in, prob, num_iterations\n",
    "\n",
    "test = [main(100) for i in range(1000)]\n",
    "test2 = [main(10) for i in range(1000)]\n",
    "print(\"N = 100: \")\n",
    "print(\"E_in: \", sum(i for i, _, _ in test) / 1000)\n",
    "print(\"E_out: \", sum(i for _, i, _ in test) / 1000)\n",
    "print (\"N = 10: \")\n",
    "print(\"Average number of iterations for PLA to converge: \", sum(i for _, _, i in test2) / 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **[c]** \n",
    "\n",
    "The E_in of 0.04 is closest to 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **[d]**\n",
    "\n",
    "The E_out of 0.0504 is closest to 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **[a]**\n",
    "\n",
    "6.229 iterations is closest to 1 iteration (closer than 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in:  0.5037600000000001\n",
      "chance of g1 agreeing with h:  0.9617010000000001\n",
      "chance of g2 agreeing with h:  0.6621519999999995\n",
      "chance of g3 agreeing with h:  0.6620479999999993\n",
      "chance of g4 agreeing with h:  0.6327049999999997\n",
      "chance of g5 agreeing with h:  0.5612019999999996\n",
      "E_out:  0.1268460000000001\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.val = np.array([1, x, y])\n",
    "        \n",
    "class Non_linear:\n",
    "    def __init__(self, x, y):\n",
    "        self.val = np.array([1, x, y, x*y, math.pow(x, 2), math.pow(y, 2)])\n",
    "        \n",
    "class Test_function:\n",
    "    def __init__(self, c1, c2, c3, c4, c5):\n",
    "        self.val = [0, c1, c2, c3, c4, c5]\n",
    "        \n",
    "def evaluate_test(non, func):\n",
    "    return np.sign(-1 - (func.val[1]*non.val[1]) + (func.val[2]*non.val[2]) + \\\n",
    "                   (func.val[3]*non.val[3]) + (func.val[4]*non.val[4]) + (func.val[5]*non.val[5]))  \n",
    "    \n",
    "        \n",
    "def random_point():\n",
    "    return Point(random.uniform(-1,1), random.uniform(-1,1))\n",
    "\n",
    "\n",
    "def evaluate(point):\n",
    "    output = np.sign(math.pow(point.val[1], 2) + math.pow(point.val[2], 2) - 0.6)\n",
    "    if random.random() < 0.1:\n",
    "        return -output\n",
    "    return output\n",
    "\n",
    "    \n",
    "def main(n):\n",
    "    data = [random_point() for x in range(n)]\n",
    "    outcomes =  list(map(lambda x: (x, evaluate(x)), data))               \n",
    "\n",
    "    X = np.zeros((n, 3))\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        X[i,:] = outcomes[i][0].val\n",
    "        y[i] = outcomes[i][1]\n",
    "        \n",
    "        \n",
    "    w = (LA.inv(X.T@X)@(X.T))@y   \n",
    "    #w = LA.pinv(X)@y\n",
    "    \n",
    "    mis = 0\n",
    "    for i in range(n):\n",
    "        if np.sign(w.dot(data[i].val)) != outcomes[i][1]:\n",
    "            mis += 1\n",
    "        \n",
    "    E_in = mis / n\n",
    "    \n",
    "    \n",
    "    data2 = [Non_linear(x.val[1], x.val[2]) for x in data]             \n",
    "\n",
    "    X_2 = np.zeros((n, 6))\n",
    "    y_2 = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        X_2[i,:] = data2[i].val\n",
    "        y_2[i] = outcomes[i][1]\n",
    "        \n",
    "    #w_2 = (LA.inv(X_2.T@X_2)@(X_2.T))@y_2 \n",
    "    w_2 = LA.pinv(X_2)@y_2\n",
    "\n",
    "    g1 = Test_function(0.05, 0.08, 0.13, 1.5, 1.5)\n",
    "    g2 = Test_function(0.05, 0.08, 0.13, 1.5, 15)\n",
    "    g3 = Test_function(0.05, 0.08, 0.13, 15, 1.5)\n",
    "    g4 = Test_function(1.5, 0.08, 0.13, 0.05, 0.05)\n",
    "    g5 = Test_function(0.05, 0.08, 1.5, 0.15, 0.15)\n",
    "    \n",
    "    g1_mis = 0\n",
    "    g2_mis = 0\n",
    "    g3_mis = 0\n",
    "    g4_mis = 0\n",
    "    g5_mis = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        if evaluate_test(data2[i], g1) != np.sign(w_2.dot(data2[i].val)):\n",
    "            g1_mis += 1\n",
    "        if evaluate_test(data2[i], g2) != np.sign(w_2.dot(data2[i].val)):\n",
    "            g2_mis += 1\n",
    "        if evaluate_test(data2[i], g3) != np.sign(w_2.dot(data2[i].val)):\n",
    "            g3_mis += 1\n",
    "        if evaluate_test(data2[i], g4) != np.sign(w_2.dot(data2[i].val)):\n",
    "            g4_mis += 1\n",
    "        if evaluate_test(data2[i], g5) != np.sign(w_2.dot(data2[i].val)):\n",
    "            g5_mis += 1  \n",
    "            \n",
    "    new_points = [random_point() for x in range(1000)]\n",
    "    new_outcomes =  list(map(lambda x: (x, evaluate(x)), new_points))   \n",
    "    new_data = [Non_linear(x.val[1], x.val[2]) for x in new_points] \n",
    "    new_mis = 0\n",
    "    for i in range(1000):\n",
    "        if np.sign(w_2.dot(new_data[i].val)) != new_outcomes[i][1]:\n",
    "            new_mis += 1\n",
    "            \n",
    "    E_out = new_mis / 1000\n",
    "    \n",
    "    \n",
    "    \n",
    "    return E_in, g1_mis / n, g2_mis / n, g3_mis / n, g4_mis / n, g5_mis / n, E_out \n",
    "\n",
    "test = [main(1000) for i in range(1000)]\n",
    "print(\"E_in: \", sum(i for i, _, _, _, _, _, _ in test) / 1000)\n",
    "print(\"chance of g1 agreeing with h: \", 1 - (sum(i for _, i, _, _, _, _, _ in test) / 1000))\n",
    "print(\"chance of g2 agreeing with h: \", 1 - (sum(i for _, _, i, _, _, _, _ in test) / 1000))\n",
    "print(\"chance of g3 agreeing with h: \", 1 - (sum(i for _, _, _, i, _, _, _ in test) / 1000))\n",
    "print(\"chance of g4 agreeing with h: \", 1 - (sum(i for _, _, _, _, i, _, _ in test) / 1000))\n",
    "print(\"chance of g5 agreeing with h: \", 1 - (sum(i for _, _, _, _, _, i, _ in test) / 1000))\n",
    "print(\"E_out: \", sum(i for _, _, _, _, _, _, i in test) / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **[d]**\n",
    "\n",
    "E_in is 0.504, which is closest to 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **[a]** \n",
    "\n",
    "Out of the 5 hypotheses, g1 agrees with w 96% of the time, which is much higher than any of the other hypotheses. Therefore, it is closest to w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **[b]** \n",
    "\n",
    "E_out is 0.127, which is closest to 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
