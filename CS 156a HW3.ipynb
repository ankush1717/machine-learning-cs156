{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 156 HW 3\n",
    "### Ankush Hommerich-Dutt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[b]**\n",
    "\n",
    "Let us manipulate the modified Hoeffding Inequality to get an expression for N:\n",
    "\n",
    "$P \\leq 2Me^{-2\\epsilon^2N} \\rightarrow \\ln{\\frac{P}{2M}} \\leq -2\\epsilon^2N \\rightarrow N \\geq -\\frac{1}{2\\epsilon^2}\\ln{\\frac{P}{2m}}$\n",
    "\n",
    "Now, let us plug in $\\epsilon=0.05, P=0.03, M=1:$\n",
    "\n",
    "$N \\geq -\\frac{1}{2(0.05)^2}\\ln{\\frac{0.03}{2}} = 839.9$\n",
    "\n",
    "and 839 is closest to 1000, which is answer choice b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **[c]**\n",
    "\n",
    "Let us use the expression for $N$ found in the previous question: $N \\geq -\\frac{1}{2\\epsilon^2}\\ln{\\frac{P}{2m}}$\n",
    "\n",
    "Now, let us plug in $\\epsilon=0.05, P=0.03, M=10:$\n",
    "\n",
    "$N \\geq -\\frac{1}{2(0.05)^2}\\ln{\\frac{0.03}{20}} = 1300.4$\n",
    "\n",
    "and 1300 is closest to 1500, which is answer choice c. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **[d]**\n",
    "\n",
    "Let us use the expression for $N$ found in question 1: $N \\geq -\\frac{1}{2\\epsilon^2}\\ln{\\frac{P}{2m}}$\n",
    "\n",
    "Now, let us plug in $\\epsilon=0.05, P=0.03, M=100:$\n",
    "\n",
    "$N \\geq -\\frac{1}{2(0.05)^2}\\ln{\\frac{0.03}{200}} = 1760.9$\n",
    "\n",
    "and 1760 is closest to 2000, which is answer choice d. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **[a]**\n",
    "\n",
    "The break point is still 4 for the perceptron model, even for the 3D case. We saw that the 2D case broke at $N=4$ for a general setup because if we took a point $a$ and then also took the point $b$ which is \"opposite\" to $a$ (not entirely sure how to mathematically define opposite, but if you were to make a polygon out of the 4 points, then it would be the point that does not have an edge connecting to $a$), and assigned them the same binary outcome (whether it is +1 or -1) and assigned the other 2 points the opposite outcome, then no perceptron line could correctly classify the 4 points. If we generalize this to 3D, the outcome still holds. Take 4 general points, and pick any point $a$. Pick the point $b$ which is \"opposite\" (in this case we dont make a polygon, but a 3D shape by connecting the 4 points in $\\mathbb R^3$ and then taking the point which does not have a face connecting to $a$) to $a$. Classify these points with the same outcome, and the other 2 points with the opposite outcome. You will not be able to find a plane that can correctly classify this outcome of the 4 points in $\\mathbb R^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **[b]**\n",
    "\n",
    "We have a formula: $m_Hn \\leq \\sum_{i=0}^{k-1} \\binom{N}{i}$ which we know holds if a hypothesis set has a break point. We know that if there is no break point, then $m_Hn = 2^N$\n",
    "\n",
    "i) We literally saw this as the growth function for the positive rays, but also this is value we get when we plug in $k=2$ for the right hand side of the above formula for a hypothesis set with a break point: $\\sum_{i=0}^{1} \\binom{N}{i} = 1 + N$\n",
    "\n",
    "ii) We also already saw this as the growth function for the positive intervals, but also we see this is value we get when we plug in $k=3$ for the right hand side of the above formula for a hypothesis set with a break point: $\\sum_{i=0}^{2} \\binom{N}{i} = 1 + N + \\binom{N}{2}$\n",
    "\n",
    "iii) This cannot be a growth function, since the number of terms in the sum grows with $\\sqrt{N}$, and we know that if the hypothesis set has a break point $k$, then the sum stops at a fixed $k-1$. \n",
    "\n",
    "iv) This also cannot be a growth function, since we know that if there is no break point, then $m_Hn = 2^N$, but if there is, then we have to satisfy $m_Hn \\leq \\sum_{i=0}^{k-1} \\binom{N}{i}$, which is a polynomial of $N$, but we can clearly see that $2^{[N/2]}$ grows faster than any polynomial of $N$.\n",
    "\n",
    "v) This is of course a growth function, as it is always the growth function whenever a hypothesis set does not have a break point.\n",
    "\n",
    "Therefore, we can see that i, ii, and v are growth functions, which is answer choice b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **[c]**\n",
    "\n",
    "This hypothesis set of two intervals has a break point of 5. If you have $N=4$, then for any of the 16 possible dichotomies, you can find two intervals which can correctly classify the points. However, with $N=5$, if the points are ${+1,-1,+1,-1,+1}$, then no two intervals can correctly classify these points (because there would need to be 3 distinct intervals to classify three distint regions of +1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **[c]**\n",
    "\n",
    "We have 3 cases for possible dichotomies: one where there are 2 distinct intervals, one where there is only 1 distinct interval (because one of the intervals has its endpoints at the same location, or both intervals share an endpoint), and one where there are 0 distinct intervals (because both intervals have their endpoints at the same location):\n",
    "\n",
    "2 distinct: $\\binom{N}{4}$\n",
    "\n",
    "1 distinct: $\\binom{N}{2}$\n",
    "\n",
    "0 distinct: $1$\n",
    "\n",
    "So together, we have $\\binom{N}{4} + \\binom{N}{2} + 1$ total possibilities for dichotomies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **[d]**\n",
    "\n",
    "We saw with 1 interval that the break point was 3, and that with 2 intervals the break point was 5. We can begin to now see the general form. If there are $M$ possible intervals, then we will have $2M + 1$ as our smallest breakpoint (since $2M+1$ points makes it possible that there are $M+1$ distinct regions of +1 and only $M$ intervals to satisfy this which causes a break)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **[b]** \n",
    "\n",
    "With $N=5$, if we had 3 points classified as +1 forming a triangle, and two points classified as -1 in the interior of this triangle, then no triangle in $\\mathbb R^2$ can be formed that can correctly classify this configuration.\n",
    "\n",
    "However, with $N=3$, we can classify all 8 possible dichotomies in $\\mathbb R^2$. If 0, 1, or 3 points are classified as +1, then this is trivial to classify with a triangle. If 2 points are classified as +1, then simply take a triangle whos edge is a line between these two points and the sole -1 point (and we know such a line exists because the perceptron model gets shattered at $N=3$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **[b]** \n",
    "\n",
    "The two concentric circle learning model is analogous to the positive interval learning model discussed in the slides. In fact, if we treat $x_1^2 + x_2^2$ as a point in $\\mathbb R$, then this is a one-to-one correspondence with the positive interval learning model. The growth function for the positive interval model was $\\binom{N+1}{2} + 1$ and so the two concentric circle model has the same growth function as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
