{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 156 HW 1\n",
    "### Ankush Hommerich-Dutt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[d]** \n",
    "\n",
    "Explanation: \n",
    "\n",
    "(1) This is not learning, since you **already know** the exact coin specifications from the mint. There is no learning that needs to be done by the machine, since it already knows by the statistical model on how to classify each coin. \n",
    "\n",
    "(2) This is supervised learning, since you are given a set of **labeled** data. It then uses this data to actual learn and create the specifications that should exist for each coin, so that future predictions can conform to these learned specifications.\n",
    "\n",
    "(3) This is reinforcement learning, since the outcome of the move is not know immediately, but later the move selected is given a grade (whether the game was won or not), and the weights for the moves in the game are tweaked accordingly. After millions of games, this grade for each move helps the computer develop a strategy for tic-tac-toe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **[a]** \n",
    "\n",
    "Explanation:\n",
    "    \n",
    "(1) This is not well suited for machine learning since there already exists a mathematical formula to classify primes, and it is not too difficult to evaluate.\n",
    "\n",
    "(2) This is well suited because there is plenty of data available for whether credit card charges resulted in fraud, and the underlying mathematical formula for this is not known, and so a machine can learn from all the data to better detect whether a credit card charge is fraudulent.\n",
    "\n",
    "(3) This is not well suited because there is nothing to be learned. There already exists formulas for this phenomenon (kinematics equations) which work very well for its purpose.\n",
    "\n",
    "(4) This is well suited because there must exist a patten for this, this is a problem that does not have any good formulas existing for it already, and there can exist lots of data on the congestion of an intersection based on the traffic light cycle. Machine learning could get to an optimal solution by looking at large amounts of data much faster than a human ever could. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **[d]** \n",
    "\n",
    "Bag 1 is the bag with only black balls, and bag 2 is the bag with one black and one white ball. Since you chose a black ball, you could have chosen either ball in bag 1, or the black ball in bag 2. This gives us 3 possibilities. Out of these 3 possibilities, 2 of them have the case where the second ball is also black (if the ball you initially picked was in bag 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **[b]**\n",
    "\n",
    "The probability that a red ball isn't chosen (a green ball is chosen) is 1-0.55=0.45.\n",
    "\n",
    "$(0.45)^{10} = 0.0003405 = 3.405 \\times 10^{-4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **[c]** \n",
    "\n",
    "The probability that a sample has $\\nu = 0$ is $3.405 \\times 10^{-4}$. Therefore, the probability that a sample does not have $\\nu = 0$ is $1 - 3.405 \\times 10^{-4} = 0.9997$. If we run a thousand samples, the chance that none of the samples has $\\nu = 0$ is $0.9997^{1000} = 0.7114$. Therefore, the chance that at least one of the samples has $\\nu = 0$ is $1 - 0.7114 = 0.2886 = 0.289$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **[e]**\n",
    "\n",
    "Based on the scoring system provided:\n",
    "\n",
    "(a) (1 x 3) + (3 x 2) + (3 x 1) = 3 + 6 + 3 = 12\n",
    "\n",
    "(b) (1 x 3) + (3 x 2) + (3 x 1) = 3 + 6 + 3 = 12\n",
    "\n",
    "(c) (1 x 3) + (3 x 2) + (3 x 1) = 3 + 6 + 3 = 12\n",
    "\n",
    "(d) (1 x 3) + (3 x 2) + (3 x 1) = 3 + 6 + 3 = 12\n",
    "\n",
    "So therefore, all hypotheses for choices a-d have an equivalent score, and so e is the correct answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for N = 10: \n",
      "The number of iterations is: 10.904 and the probability of f(x) != g(x):  0.11314700000000008\n",
      "for N = 100: \n",
      "The number of iterations is: 110.125 and the probability of f(x) != g(x):  0.01432399999999998\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.val = (x, y)\n",
    "        \n",
    "    def outcome(self, line):\n",
    "        target = line.evaluate(self.val[0])\n",
    "        if self.val[1] > target:\n",
    "            return 1\n",
    "        return -1\n",
    "        \n",
    "class Line:\n",
    "    def __init__(self, point1, point2):\n",
    "        self.slope = (point2.val[1] - point1.val[1]) / (point2.val[0] - point1.val[0])\n",
    "        self.intercept = (self.slope * (-point1.val[0])) + point1.val[1]\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        return (self.slope * x) + self.intercept\n",
    "    \n",
    "class Weight_vector:\n",
    "    def __init__(self):\n",
    "        self.vec = [0,0,0]\n",
    "    \n",
    "    def dot(self, point):\n",
    "        sum = 0\n",
    "        for i in range(3):\n",
    "            if i == 0:\n",
    "                sum += self.vec[i]\n",
    "            else:    \n",
    "                sum += self.vec[i] * point.val[i - 1]\n",
    "        return sum   \n",
    "    \n",
    "    def update(self, y, x1, x2, x3):\n",
    "        self.vec[0] += y*x1\n",
    "        self.vec[1] += y*x2\n",
    "        self.vec[2] += y*x3\n",
    "        \n",
    "def random_point():\n",
    "    return Point(random.uniform(-1,1), random.uniform(-1,1))\n",
    "\n",
    "def target_function():\n",
    "    point1 = random_point()\n",
    "    point2 = random_point()\n",
    "    return Line(point1, point2)\n",
    "\n",
    "def sign(x):\n",
    "    if x < 0:\n",
    "        return -1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def iteration(outcomes, weight_vec, target):\n",
    "    mis = [i[0] for i in outcomes if sign(weight_vec.dot(i[0])) != i[1]]\n",
    "    if len(mis) == 0:\n",
    "        return True\n",
    "    bad_point = mis[random.randint(0,len(mis) - 1)]\n",
    "    weight_vec.update(bad_point.outcome(target), 1, bad_point.val[0], bad_point.val[1])\n",
    "    \n",
    "    return False\n",
    "    \n",
    "def main(n):\n",
    "    target = target_function()\n",
    "    data = [random_point() for x in range(n)]\n",
    "    outcomes =  list(map(lambda x: (x,x.outcome(target)), data))\n",
    "    weight = Weight_vector()\n",
    "    \n",
    "    converge = False \n",
    "    num_iterations = 0\n",
    "    while converge != True:\n",
    "        converge = iteration(outcomes, weight, target)\n",
    "        num_iterations += 1\n",
    "        \n",
    "    new_data = [random_point() for x in range(1000)]\n",
    "    new_outcomes =  list(map(lambda x: (x,x.outcome(target)), new_data))\n",
    "    mis = [i[0] for i in new_outcomes if sign(weight.dot(i[0])) != i[1]]\n",
    "    prob = len(mis) / 1000\n",
    "    \n",
    "    return num_iterations, prob\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "test = [main(10) for i in range(1000)]\n",
    "\n",
    "num_iterations = 0\n",
    "prob = 0\n",
    "for i in range(1000):\n",
    "    num_iterations += test[i][0]\n",
    "    prob += test[i][1]\n",
    "    \n",
    "print(\"for N = 10: \\nThe number of iterations is:\", num_iterations / 1000, \n",
    "      \"and the probability of f(x) != g(x): \", prob / 1000)    \n",
    "\n",
    "\n",
    "\n",
    "test2 = [main(100) for i in range(1000)]\n",
    "\n",
    "num_iterations2 = 0\n",
    "prob2 = 0\n",
    "for i in range(1000):\n",
    "    num_iterations2 += test2[i][0]\n",
    "    prob2 += test2[i][1]\n",
    "    \n",
    "print(\"for N = 100: \\nThe number of iterations is:\", num_iterations2 / 1000, \n",
    "      \"and the probability of f(x) != g(x): \", prob2 / 1000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **[b]** \n",
    "\n",
    "15.793 is closest to 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **[c]** \n",
    "\n",
    "0.112 is closest to 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **[b]** \n",
    "\n",
    "194.062 is closest to 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **[b]** \n",
    "\n",
    "0.014 is closest to 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
